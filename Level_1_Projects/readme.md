# Deep Learning and Neural Network Projects

This folder contains multiple projects exploring **deep learning**, **neural networks**, and **optimization techniques**. The projects use real-world datasets to implement CNNs, RNNs, face recognition, and experiment with different architectures, optimizers, and regularization methods.

---

## 1. CNN (FashionMNIST)
A convolutional neural network built to classify images from the **FashionMNIST** dataset.

**Features:**
- Image preprocessing and normalization.
- CNN architecture with convolutional, pooling, and fully connected layers.
- Model evaluation using accuracy and loss metrics.

**Technologies:** Python, PyTorch, Matplotlib

---

## 2. CNN_Variants
Explores different CNN architectures and variants for image classification.

**Features:**
- Implementation of multiple CNN variants.
- Comparison of model performance on benchmark datasets.

---

## 3. Face_Recognition
A face recognition system using deep learning.

**Features:**
- Face detection and encoding.
- Identification of individuals from images.
- Real-time recognition support.

**Technologies:** Python, OpenCV, PyTorch

---

## 4. Optimization_Algorithms
Compares the effect of different optimization algorithms on neural network training.

**Features:**
- Implementation and testing of optimizers like SGD, Adam, RMSprop.
- Analysis of convergence, training speed, and accuracy.

---

## 5. RNN (IMDB Sentiment Analysis)
A recurrent neural network for sentiment analysis on the **IMDB movie review dataset**.

**Features:**
- Text preprocessing and tokenization.
- Training an RNN for binary sentiment classification.
- Evaluation of model performance.

**Technologies:** Python, PyTorch, NLTK

---

## 6. RNN_LSTM_GRU
Extends the RNN project with **LSTM** and **GRU** architectures for improved performance.

**Features:**
- Compare vanilla RNN, LSTM, and GRU models.
- Analyze accuracy and training stability.

---

## 7. Regularization_Techniques
Demonstrates various neural network regularization techniques.

**Features:**
- Dropout, weight decay, batch normalization.
- Analysis of overfitting reduction.
- Performance comparison with baseline models.

---

## 8. SLP_MLP (Regression Project)
Compares **Single-Layer Perceptron (SLP)** and **Multi-Layer Perceptron (MLP)** models for regression tasks.

**Features:**
- Implement SLP and MLP architectures.
- Compare regression accuracy and loss.
- Highlight the advantages of deep networks over shallow ones.

---

## Overall Outcome
This collection of projects provides a **comprehensive deep learning foundation**, including CNNs, RNNs, optimizers, regularization techniques, and practical applications like sentiment analysis and face recognition. It is ideal for understanding neural network behavior, model comparison, and optimization in real-world tasks.
